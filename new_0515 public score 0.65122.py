# -*- coding: utf-8 -*-
"""New_0515

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/kidujung2/new-0515.4a7fc6a8-1e4a-4799-b5f1-73f862c1f687.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250604/auto/storage/goog4_request%26X-Goog-Date%3D20250604T060459Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4f1b2647d3b97bc7e78024ec7bb4738f0c5cc7370cd954fa434513cf10dcc2dc348fa743cbd5e4ff4ff7f5f2500c0b40001ba1c3991769929e76f67254835f40d50f2878ef247a0ab892acead5633a90718e0a93a0e568332e661229f428200031d5649e0656b6aa07d04da5b3e28c1d1d43cf0227e950d6008e167fa74e2106677edad9193ed2a991ef7c63f6f53a5423673fec11bb6f84a24550bc711f5d4d1238a6f06c004ba9c7b7805bfdbe07aa1e440c435c5793e742cda2cf80154bcf63eeea8fcb68a92faceacbac570949974da137af8444c7df5538d9e91714239894880527e9f1810f79f2b4438b8bc3742470e7a440e89b3ed2019a5111bdba1c
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

uou_ie_g_03874_spring_2025_term_project_path = kagglehub.competition_download('uou-ie-g-03874-spring-2025-term-project')

print('Data source import complete.')

"""# 라이브러리"""

!pip install -U scikit-learn==1.3.2 imbalanced-learn==0.11.0

# Basic Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import matplotlib
import warnings
warnings.filterwarnings(action='ignore')

# Model Evaluation
from sklearn.metrics import (accuracy_score, f1_score, classification_report, confusion_matrix)
from sklearn.preprocessing import StandardScaler
from sklearn.utils.class_weight import compute_class_weight
from scipy.stats import mode

# Data Splitting and Cross-Validation
from sklearn.model_selection import (train_test_split, StratifiedKFold, RandomizedSearchCV)

# Classification Models
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# Oversampling
from imblearn.over_sampling import SMOTE

"""# 데이터 불러오기"""

x_train = pd.read_csv('/kaggle/input/uou-ie-g-03874-spring-2025-term-project/ML_x_train.csv')
x_test = pd.read_csv('/kaggle/input/uou-ie-g-03874-spring-2025-term-project/ML_x_test.csv')
y_train = pd.read_csv('/kaggle/input/uou-ie-g-03874-spring-2025-term-project/ML_y_train.csv')

x_train

y_train

x_test

"""# 데이터 분석

[참고] Credit Score Classification Part:1 Data Cleaning

 - https://www.kaggle.com/code/clkmuhammed/credit-score-classification-part-1-data-cleaning#B.-Examining-the-Data
"""

# 숫자를 지수표기법(e) 대신 소수점 두 자리로 표시
pd.options.display.float_format = '{:.2f}'.format

# train/test 데이터 크기 확인
x_train.shape, x_test.shape

x_train.info()

x_test.info()

y_train.info()

x_train.describe().T

# std는 표준편차, mean 평균, min 최소, max 최대

x_test.describe().T

y_train.describe().T

"""# 데이터 전처리

## 1. 데이터 통합 (x_train/test)
"""

# train/test 데이터 통합 (데이터 전처리하고 다시 분리 예정)
x_train['is_train'] = 1
x_test['is_train'] = 0
x = pd.concat([x_train, x_test], ignore_index=True)
x.shape

x.describe().T

"""## 2. 결측치 확인"""

# 각 열 결측치 개수 확인
x.isna().sum()

# 각 열의 결측치 비율 확인
x.isnull().mean()*100

"""## 3. 이상치 확인"""

x_copy = x.copy()
x_copy.shape

x = x_copy
x.info()

"""## 4. 이상치, 결측값 처리

[참고] Credit score classification 80% score 7 models

https://www.kaggle.com/code/abdelaziznabil/credit-score-classification-80-score-7-models
"""

def Distribution(column, data, i):
    fig, ax = plt.subplots(1, 2, figsize=(15, 5))
    title = ['Before Distribution', 'After Distribution']
    sns.set(style='whitegrid')

    if i == 0:
        sns.kdeplot(data=data, x=column, ax=ax[0], color='r').set_title(title[i])
        sns.boxplot(data=data, x=column, ax=ax[1], palette='magma').set_title(title[i])
    else:
        sns.kdeplot(data=data, x=column, ax=ax[0], color='#2171b5').set_title(title[i])
        sns.boxplot(data=data, x=column, ax=ax[1], color='#2171b5').set_title(title[i])

    plt.tight_layout()

"""## Age 만 나이"""

# 전처리 전 시각화
Distribution(column='Age',data=x,i=0)

# 이상치 처리 및 음수 제거: 20 ~ 100 범위 유효
x.loc[(x['Age'] < 20) | (x['Age'] > 100), 'Age'] = np.nan

# 결측값 처리: Occupation 그룹 기준 중앙값 대체
x['Age'] = x.groupby('Occupation')['Age'].transform(lambda x: x.ffill().bfill())
x['Age'].fillna(x['Age'].median(), inplace=True)

# 전처리 후 시각화
Distribution(column='Age',data=x,i=1)

"""## Annual_Income 연간 총 소득"""

# 전처리 전 시각화
Distribution(column='Annual_Income', data=x, i=0)

# 음수 또는 0 → NaN 처리
x.loc[x['Annual_Income'] <= 0, 'Annual_Income'] = np.nan

# 100만 초과도 NaN 처리
x.loc[x['Annual_Income'] > 1_000_000, 'Annual_Income'] = np.nan

# 결측값 처리
x['Annual_Income'].fillna(x['Annual_Income'].median(), inplace=True)

# 전처리 후 시각화
Distribution(column='Annual_Income', data=x, i=1)

"""## Monthly_Inhand_Salary 매월 실수령액"""

# 전처리 전 시각화
Distribution(column='Monthly_Inhand_Salary', data=x, i=0)

# 결측값 처리: Annual_Income 기반 유추
miss_salary = x['Monthly_Inhand_Salary'].isna()
x.loc[miss_salary, 'Monthly_Inhand_Salary'] = x.loc[miss_salary, 'Annual_Income'] / 12

# 전처리 후 시각화
Distribution(column='Monthly_Inhand_Salary', data=x, i=1)

"""## Num_Bank_Accounts 보유 중인 은행 계좌 수"""

# 전처리 전 시각화
Distribution(column='Num_Bank_Accounts', data=x, i=0)

# 이상치 처리: 0~11 범위 외 제거, 결측값은 최빈값으로 대체
x.loc[(x['Num_Bank_Accounts'] < 0) | (x['Num_Bank_Accounts'] > 11), 'Num_Bank_Accounts'] = np.nan
x['Num_Bank_Accounts'].fillna(x['Num_Bank_Accounts'].mode()[0], inplace=True)

# 전처리 후 시각화
Distribution(column='Num_Bank_Accounts', data=x, i=1)

"""## Num_Credit_Card 보유 중인 신용카드 수"""

# 전처리 전 시각화
Distribution(column='Num_Credit_Card', data=x, i=0)

# 이상치 처리: 11 초과 제거, 결측값은 최빈값으로 대체
x.loc[x['Num_Credit_Card'] > 11, 'Num_Credit_Card'] = np.nan
x['Num_Credit_Card'].fillna(x['Num_Credit_Card'].mode()[0], inplace=True)

# 전처리 후 시각화
Distribution(column='Num_Credit_Card', data=x, i=1)

"""Interest_Rate 대출 이자율Interest_Rate Interest_Rate 대출 이자율"""

# 전처리 전 시각화
Distribution(column='Interest_Rate', data=x, i=0)

# 이상치 처리: 34 초과 제거, 결측값은 최빈값으로 대체
x.loc[x['Interest_Rate'] > 34, 'Interest_Rate'] = np.nan
x['Interest_Rate'].fillna(x['Interest_Rate'].mode()[0], inplace=True)

# 전처리 후 시각화
Distribution(column='Interest_Rate', data=x, i=1)

"""## Num_of_Loan 대출 건수"""

# 전처리 전 시각화
Distribution(column='Num_of_Loan', data=x, i=0)

# 이상치 제거: 음수 및 9 초과 제거, 결측값 중앙값 대체
x.loc[(x['Num_of_Loan'] < 0) | (x['Num_of_Loan'] > 9), 'Num_of_Loan'] = np.nan
x['Num_of_Loan'].fillna(x['Num_of_Loan'].median(), inplace=True)

# 전처리 후 시각화
Distribution(column='Num_of_Loan', data=x, i=1)

"""## Num_of_Delayed_Payment 연체 횟수"""

# 전처리 전 시각화
Distribution(column='Num_of_Delayed_Payment', data=x, i=0)

# 이상치 제거: 음수 및 28 초과 제거, 중앙값 대체
x.loc[(x['Num_of_Delayed_Payment'] < 0) | (x['Num_of_Delayed_Payment'] > 28), 'Num_of_Delayed_Payment'] = np.nan
x['Num_of_Delayed_Payment'].fillna(x['Num_of_Delayed_Payment'].median(), inplace=True)

# 전처리 후 시각화
Distribution(column='Num_of_Delayed_Payment', data=x, i=1)

"""## Num_Credit_Inquiries 신용 조회 횟수"""

# 전처리 전 시각화
Distribution(column='Num_Credit_Inquiries', data=x, i=0)

# 결측값 처리: 중앙값 대체
x['Num_Credit_Inquiries'].fillna(x['Num_Credit_Inquiries'].median(), inplace=True)

# 전처리 후 시각화
Distribution(column='Num_Credit_Inquiries', data=x, i=1)

"""## Outstanding_Debt 미상환 부채 금액"""

# 전처리 전 시각화
Distribution(column='Outstanding_Debt', data=x, i=0)

# 결측값 처리: 중앙값 대체
x['Outstanding_Debt'].fillna(x['Outstanding_Debt'].median(), inplace=True)

# 전처리 후 시각화
Distribution(column='Outstanding_Debt', data=x, i=1)

"""## Credit_Utilization_Ratio 신용 사용률 (사용 금액 / 한도)"""

# 전처리 전 시각화
Distribution(column='Credit_Utilization_Ratio', data=x, i=0)

# 결측값 처리: 중앙값 대체
x['Credit_Utilization_Ratio'].fillna(x['Credit_Utilization_Ratio'].median(), inplace=True)

# 전처리 후 시각화
Distribution(column='Credit_Utilization_Ratio', data=x, i=1)

"""## Total_EMI_per_month 월별 총 상환금 (원금 및 이자 포함)"""

# 전처리 전 시각화
Distribution(column='Total_EMI_per_month', data=x, i=0)

# 결측값 처리: 중앙값 대체
x['Total_EMI_per_month'].fillna(x['Total_EMI_per_month'].median(), inplace=True)

# 전처리 후 시각화
Distribution(column='Total_EMI_per_month', data=x, i=1)

"""## Amount_invested_monthly 월별 투자 금액"""

# 전처리 전 시각화
Distribution(column='Amount_invested_monthly', data=x, i=0)

# 결측값 처리: 중앙값 대체
x['Amount_invested_monthly'].fillna(x['Amount_invested_monthly'].median(), inplace=True)

# 전처리 후 시각화
Distribution(column='Amount_invested_monthly', data=x, i=1)

"""## Monthly_Balance 월별 계좌 잔액"""

# 전처리 전 시각화
Distribution(column='Monthly_Balance', data=x, i=0)

# 결측값 처리: 중앙값 대체
x['Monthly_Balance'].fillna(x['Monthly_Balance'].median(), inplace=True)

# 전처리 후 시각화
Distribution(column='Monthly_Balance', data=x, i=1)

"""## Credit_History_Months 신용 거래 기간 (월)"""

# 전처리 전 시각화
Distribution(column='Credit_History_Months', data=x, i=0)

# 이상치 제거: 720개월 초과 제거, 중앙값 대체
x.loc[x['Credit_History_Months'] > 720, 'Credit_History_Months'] = np.nan
x['Credit_History_Months'].fillna(x['Credit_History_Months'].median(), inplace=True)

# 전처리 후 시각화
Distribution(column='Credit_History_Months', data=x, i=1)

# 이상치 클리핑 (IQR)
def clip_outliers(df, columns):
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)

# 클리핑 적용 대상 변수
clip_columns = [
    'Annual_Income', 'Delay_from_due_date', 'Num_Credit_Inquiries', 'Outstanding_Debt',
    'Monthly_Inhand_Salary', 'Credit_Utilization_Ratio', 'Total_EMI_per_month',
    'Amount_invested_monthly', 'Monthly_Balance', 'Num_Credit_Inquiries', 'Outstanding_Debt'
]

# 이상치 클리핑 실행
clip_outliers(x, clip_columns)

# 이상치 boxplot 시각화
def plot_multiple_outliers(df):
    numeric_cols = df.select_dtypes(include=['number']).columns
    n = len(numeric_cols)

    plt.figure(figsize=(10, 2 * n))

    for i, col in enumerate(numeric_cols, 1):
        plt.subplot(n, 1, i)
        sns.boxplot(x=df[col])
        plt.title(f'Boxplot for {col}')
        plt.tight_layout()

    plt.show()

# 이상치 시각화 실행
plot_multiple_outliers(x)

x

x.describe().T

x.isna().sum()

x.info()

"""## 5. 파생변수"""

x_train['Credit_Score'] = y_train['Credit_Score']
x_train_filtered = x_train[x_train['Credit_Score'].isin([0, 2])].copy()

# 필터링 후 파생변수 생성
x_train_filtered['Delayed_Payment_Ratio'] = x_train_filtered['Num_of_Delayed_Payment'] / (x_train_filtered['Credit_History_Months'] + 1)
x_train_filtered['Balance_to_EMI'] = x_train_filtered['Monthly_Balance'] / (x_train_filtered['Total_EMI_per_month'] + 1)
x_train_filtered['Salary_Ratio'] = x_train_filtered['Monthly_Inhand_Salary'] / (x_train_filtered['Monthly_Balance'] + 1)

# 다시 복사본 생성 (파생변수 포함 보장)
x_plot = x_train_filtered.copy()

derived_cols = ['Delayed_Payment_Ratio', 'Balance_to_EMI', 'Salary_Ratio']

# 모든 파생변수를 수치형으로 강제 변환
for col in derived_cols:
    if col in x_plot.columns:
        x_plot[col] = pd.to_numeric(x_plot[col], errors='coerce')

def safe_kde_plot(data, column):
    # 복사 및 클리닝
    d = data[[column, 'Credit_Score']].copy()
    d = d.replace([np.inf, -np.inf], np.nan)
    d = d.dropna()

    # KDE 시각화
    plt.figure(figsize=(10, 5))
    sns.kdeplot(data=d[d['Credit_Score'] == 0], x=column, label='Credit Score 0', fill=True)
    sns.kdeplot(data=d[d['Credit_Score'] == 2], x=column, label='Credit Score 2', fill=True)
    plt.title(f'Distribution of {column} by Credit Score (0 vs 2)')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

safe_kde_plot(x_train_filtered, 'Delayed_Payment_Ratio')
safe_kde_plot(x_train_filtered, 'Balance_to_EMI')
safe_kde_plot(x_train_filtered, 'Salary_Ratio')

x['Delayed_Payment_Ratio'] = x['Num_of_Delayed_Payment'] / (x['Credit_History_Months'] + 1)
x['Balance_to_EMI'] = x['Monthly_Balance'] / (x['Total_EMI_per_month'] + 1)
x['Salary_Ratio'] = x['Monthly_Inhand_Salary'] / (x['Monthly_Balance'] + 1)

"""## 6. 전처리 이후 데이터 분리"""

# is_train 값이 1인 데이터는 학습용, 0인 데이터는 테스트용으로 분리
# 분리 후 'is_train' 컬럼은 필요 없으므로 drop
x_train = x[x['is_train'] == 1].drop(columns='is_train')
x_test = x[x['is_train'] == 0].drop(columns='is_train')

x_train.shape, x_test.shape

x_train.info()

x_test.info()

"""## 7. 변수 상관관계 분석

[참고] Credit Score Multi-Class Classification Part:2 ML

 - https://www.kaggle.com/code/clkmuhammed/credit-score-multi-class-classification-part-2-ml#Import-Libraries
"""

# 변수 간 상관관계
numeric_cols = x_train.select_dtypes(include='number').columns

# 상관관계 행렬 계산
corr_matrix = x_train[numeric_cols].corr()

# 히트맵 시각화
plt.figure(figsize=(16, 12))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True, linewidths=0.5)
plt.title('Correlation Heatmap (Numeric Features)', fontsize=16)
plt.tight_layout()
plt.show()

# Credit_Score 클래스 분포
train = pd.concat([x_train, y_train], axis=1)

plt.figure(figsize=(6, 4))
sns.countplot(x='Credit_Score', data=train, palette='Set2')

plt.xlabel('Credit Class')
plt.ylabel('Count')
plt.show()

# 수치형 변수 자동 선택
numeric_cols = train.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Credit_Score는 범주형 기준이므로 제외하지 않음
ncols = 3
nrows = (len(numeric_cols) + ncols - 1) // ncols
plt.figure(figsize=(16, 5 * nrows))

for i, col in enumerate(numeric_cols):
    plt.subplot(nrows, ncols, i + 1)
    sns.boxplot(data=train, x='Credit_Score', y=col, palette='Set2')
    plt.title(f'{col}')

plt.tight_layout()
plt.show()

"""# 모델링

## 1. SHAP 시각화

[참고] XGBoost explainability with SHAP
https://www.kaggle.com/code/bryanb/xgboost-explainability-with-shap

머신러닝 모델은 예측 정확도는 높지만, 그 결과가 왜 그렇게 나왔는지 해석하기 어려운 경우가 많습니다.
특히 XGBoost, RandomForest, CatBoost 같은 복잡한 앙상블 모델은 내부 구조가 블랙박스처럼 작동하여,
각 피처가 예측에 어떤 영향을 주었는지 파악하기 힘든 문제가 발생합니다.

즉, 모델은 잘 작동하고 있지만, '왜 그렇게 예측했는가?'에 대한 설명이 부족하기 때문에
결정에 대한 신뢰도가 떨어지고, 실제 적용 현장에서 문제가 발생할 수 있습니다.

이러한 상황에서 SHAP은 각 피처가 예측 결과에 얼마나, 어떻게 영향을 미쳤는지를 정량적으로 설명해줍니다.
각 피처의 기여도를 수치로 표현할 뿐만 아니라, 이를 직관적인 시각화로 제공하여
복잡한 모델의 예측 과정을 사람도 이해할 수 있도록 돕는 도구입니다.
"""

# 중요 변수 선택 전 XGBoost 학습
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
xgb_model.fit(x_train, y_train.values.ravel())

# SHAP 시각화
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(x_train)

shap.summary_plot(shap_values, x_train, plot_type="bar")

# 중요 변수 15개 추출 및 선택
importance = xgb_model.feature_importances_
importance_df = pd.DataFrame({'feature': x_train.columns, 'importance': importance})
selected_c = importance_df.sort_values(by='importance', ascending=False)['feature'].head(15).tolist()

x_train_top = x_train[selected_c].copy()
x_test_top = x_test[selected_c].copy()

# 클래스 가중치 자동 계산
class_weights = compute_class_weight(class_weight='balanced',
                                     classes=np.unique(y_train['Credit_Score']),
                                     y=y_train['Credit_Score'])

# 딕셔너리 형태로 변환
class_weight_dict = dict(zip(np.unique(y_train['Credit_Score']), class_weights))
print("클래스 가중치:", class_weight_dict)

"""*SMOTE 적용*

[참고] IQR을 이용한 Outlier 탐지 + SMOTE Oversampling
 - https://www.kaggle.com/code/dogdriip/iqr-outlier-smote-oversampling/code#SMOTE-%EC%98%A4%EB%B2%84%EC%83%98%ED%94%8C%EB%A7%81-%EC%A0%81%EC%9A%A9


**SMOTE 오버샘플링 적용**

레이블이 불균형한 분포를 가진 데이터 세트를 학습시킬 때 예측 성능의 문제가 발생할 수 있는데, 이는 이상 레이블을 가지는 데이터 건수가 정상 레이블을 가진 데이터 건수에 비해 너무 적기 때문에 발생합니다. 즉 이상 레이블을 가지는 데이터 건수는 매우 적기 때문에 제대로 다양한 유형을 학습하지 못하는 반면, 정상 레이블을 가지는 데이터 건수는 매우 많기 때문에 일방적으로 정상 레이블로 치우친 학습을 수행해 제대로 된 이상 데이터 검출이 어려워지기 쉽습니다.

오버 샘플링은 이상 데이터와 같이 적은 데이터 세트를 증식하여 학습을 위한 충분한 데이터를 확보하는 방법입니다. 원본 데이터의 피쳐 값들을 아주 약간만 변경하여 증식합니다. 대표적으로 SMOTE(Synthetic Minority Over-sampling Technique) 방법이 있습니다. SMOTE는 적은 데이터 세트에 있는 개별 데이터들의 K-Nearest-Neighbor를 찾아서 이 데이터와 K개 이웃들의 차이를 일정 값으로 만들어서 기존 데이터와 약간 차이가 나는 새로운 데이터들을 생성하는 방식입니다.
"""

# 데이터 분할 → SMOTE는 학습 데이터에만 먼저 적용
x_trn, x_val, y_trn, y_val = train_test_split(
    x_train_top, y_train['Credit_Score'], test_size=0.2, random_state=42, stratify=y_train['Credit_Score'])

"""## 3. 각 모델 선정 및 최적 하이퍼파라미터 설정"""

# 각 모델과 최적 하이퍼파라미터 설정
rf = RandomForestClassifier(random_state=42, class_weight=class_weight_dict)
rf_params = {
    'n_estimators': [200, 300],
    'max_depth': [15, 20],
    'min_samples_split': [2, 4],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt']
}

xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
xgb_params = {
    'n_estimators': [200, 300],
    'learning_rate': [0.03, 0.05],
    'max_depth': [6, 8],
    'subsample': [0.8],
    'colsample_bytree': [1.0],
    'gamma': [0.1, 0.3]
}

gb = GradientBoostingClassifier(random_state=42)
gb_params = {
    'n_estimators': [100, 200],
    'max_depth': [5, 6],
    'learning_rate': [0.01, 0.05],
    'subsample': [0.6, 0.8]
}

# 모델별 RandomizedSearchCV 실행하여 최적 하이퍼파라미터 선정
def tune_model(model, param_grid, name='model'):
    search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=20,
                                scoring='f1_macro', cv=3, verbose=1, random_state=42, n_jobs=-1)
    search.fit(x_trn, y_trn)

    # 최적 하이퍼파라미터 출력 및 저장
    print(f"\n{name} Best Params:", search.best_params_)
    return search.best_estimator_, search.best_params_

# 하이퍼파라미터 튜닝 실행
print("\nRandomForest")
best_rf, best_rf_params = tune_model(rf, rf_params, name="RandomForest")

print("\nXGBoost")
best_xgb, best_xgb_params = tune_model(xgb, xgb_params, name="XGBoost")

print("\nGradientBoosting")
best_gb, best_gb_params = tune_model(gb, gb_params, name="GradientBoosting")

"""## 4. 개별 모델별 성능 평가"""

def evaluate_model(name, model, x_data, y_data):
    model.fit(x_data, y_data)
    y_pred = model.predict(x_data)
    acc = accuracy_score(y_data, y_pred)
    f1 = f1_score(y_data, y_pred, average='macro')
    print(f"\n[{name}]")
    print("Accuracy:", acc)
    print("Macro F1:", f1)
    print(classification_report(y_data, y_pred))

evaluate_model("RandomForest", best_rf, x_trn, y_trn)
evaluate_model("XGBoost", best_xgb, x_trn, y_trn)
evaluate_model("GradientBoosting", best_gb, x_trn, y_trn)

base_models = [
    ('rf', best_rf),
    ('xgb', best_xgb),
    ('gb', best_gb),
]

meta_model = XGBClassifier(
    **best_xgb_params,
    reg_alpha=0.3,        # L1 penalty
    reg_lambda=1.0,       # L2 penalty
    use_label_encoder=False,
    eval_metric='mlogloss',
    random_state=42
)

stack_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    stack_method='predict',
    cv=5,
    passthrough=True,
    n_jobs=-1
)

# StratifiedKFold로 검증
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
acc_scores = []
f1_scores = []

for fold, (train_idx, valid_idx) in enumerate(skf.split(x_train, y_train), 1):
    X_tr, X_val = x_train.iloc[train_idx], x_train.iloc[valid_idx]
    y_tr, y_val = y_train.iloc[train_idx].values.ravel(), y_train.iloc[valid_idx].values.ravel()

    # fold마다 새로운 stacking model 생성
    fold_stack_model = StackingClassifier(
        estimators=base_models,
        final_estimator=meta_model,
        stack_method='predict',
        passthrough=True,
        cv=5,
        n_jobs=-1
    )
    fold_stack_model.fit(X_tr, y_tr)
    val_preds = fold_stack_model.predict(X_val)

    acc = accuracy_score(y_val, val_preds)
    f1 = f1_score(y_val, val_preds, average='macro')
    acc_scores.append(acc)
    f1_scores.append(f1)
    print(f"[Fold {fold}] Accuracy: {acc:.4f}, Macro F1: {f1:.4f}")

print(f"\nK-Fold Accuracy: {np.mean(acc_scores):.4f}")
print(f"K-Fold Macro F1: {np.mean(f1_scores):.4f}")

stack_model.fit(x_train, y_train)

# train 전체에서 예측 및 오분류 진단
y_true = y_train.values.ravel() if hasattr(y_train, 'values') else y_train
y_pred_stack = stack_model.predict(x_train)
mis_idx = np.where(y_true != y_pred_stack)[0]
print(f"예측 실패 샘플 수: {len(mis_idx)} / {len(y_true)}")

fail_df = pd.DataFrame({'True': y_true[mis_idx], 'Pred': y_pred_stack[mis_idx]})
print("\n실패 클래스 조합 (True → Pred):")
print(fail_df.value_counts().sort_values(ascending=False))
print("\nConfusion Matrix:")
print(confusion_matrix(y_true, y_pred_stack))

fail_features = x_train.iloc[mis_idx].copy()
fail_features['True'] = y_true[mis_idx]
fail_features['Pred'] = y_pred_stack[mis_idx]
example = fail_features[(fail_features['True'] == 1) & (fail_features['Pred'] == 0)]
print("\n클래스 1을 0으로 잘못 예측한 사례 수:", len(example))

"""# Submission 결과 제출"""

np.random.seed(42)

x_test_aligned = x_test[x_train.columns.tolist()].copy()

best_rf.fit(x_train, y_train)
best_gb.fit(x_train, y_train)
best_xgb.fit(x_train, y_train)

pred_rf = best_rf.predict(x_test_aligned)
pred_gb = best_gb.predict(x_test_aligned)
pred_xgb = best_xgb.predict(x_test_aligned)
pred_stack = stack_model.predict(x_test_aligned)
proba_stack = stack_model.predict_proba(x_test_aligned)

all_preds = np.vstack([
    pred_rf,
    pred_rf,
    pred_rf,
    pred_xgb,
    pred_stack
])

pred_test, _ = mode(all_preds, axis=0)
pred_test = pred_test.flatten()

# 확률 기반 후처리 함수 (rf/xgb 조건 없이 확률조건만)
def postprocess_correction(pred_test, proba_stack, threshold=0.40, verbose=True):
    pred_test_corrected = pred_test.copy()
    changed_idx = []
    for i in range(len(pred_test)):
        if pred_test[i] == 2 and proba_stack[i][2] < threshold:
            pred_test_corrected[i] = 1
            changed_idx.append(i)
    if verbose:
        print(f"교정 전 class 2 예측 개수: {np.sum(pred_test == 2)}")
        print(f"교정 후 class 2 예측 개수: {np.sum(pred_test_corrected == 2)}")
        print(f"실제로 교정된 샘플 수: {len(changed_idx)}")
        if len(changed_idx) > 0:
            print("교정된 인덱스(일부):", changed_idx[:10])
    return pred_test_corrected, changed_idx

# 후처리 실행 (threshold=0.40)
final_pred, changed_idx = postprocess_correction(
    pred_test, proba_stack, threshold=0.40, verbose=True
)

# 제출 파일 템플릿 로드
result = pd.read_csv('/kaggle/input/uou-ie-g-03874-spring-2025-term-project/ML_sample_submission.csv')

# 예측 결과 삽입
result['Credit_Score'] = final_pred

# 저장
result.to_csv('submission.csv', index=False)