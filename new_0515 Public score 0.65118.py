# -*- coding: utf-8 -*-
"""New_0515

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/kidujung2/new-0515.c261e38e-01c4-4dcd-8547-f977d6a25416.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250604/auto/storage/goog4_request%26X-Goog-Date%3D20250604T060408Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da5215e8caf0e48c619377da684cd07b01edeb3fe198ab2941f08d73b6a40f4445674c57259bc5dff42add55a3cb3aa4109c3232cce6985dd96ff88e8236220c7d40459ff341ed40d0cacedd1fe1ea924d1df6f2013df8dc6d23dd95a923a0bf23c0d83ffbdb3a1e75d9e3d9b6e55a2110520d6851753feb72bccdfc3a5074ae87ea1dd1197e26447d4902bc8e0d50ea2688585a40b90070820607d6871699c2f377fff20d11d8af867d2888fbe22c952e5f606889bc7ff2c0335b416140524838d85756e83e68671495a0f607a506af5fe3fcfc5d323bdb916f1d788255c946388c724b08d3f3ccd03c7dbc6d965f39be5ff95a11df479bd809ae6ab948a6b7a
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

uou_ie_g_03874_spring_2025_term_project_path = kagglehub.competition_download('uou-ie-g-03874-spring-2025-term-project')

print('Data source import complete.')

"""# 라이브러리"""

!pip install -U scikit-learn==1.3.2 imbalanced-learn==0.11.0

# Basic Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import matplotlib
import warnings
warnings.filterwarnings(action='ignore')

# Model Evaluation
from sklearn.metrics import (accuracy_score, f1_score, classification_report, confusion_matrix)
from sklearn.preprocessing import StandardScaler
from sklearn.utils.class_weight import compute_class_weight
from scipy.stats import mode

# Data Splitting and Cross-Validation
from sklearn.model_selection import (train_test_split, StratifiedKFold, RandomizedSearchCV)

# Classification Models
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# Oversampling
from imblearn.over_sampling import SMOTE

"""# 데이터 불러오기"""

x_train = pd.read_csv('/kaggle/input/uou-ie-g-03874-spring-2025-term-project/ML_x_train.csv')
x_test = pd.read_csv('/kaggle/input/uou-ie-g-03874-spring-2025-term-project/ML_x_test.csv')
y_train = pd.read_csv('/kaggle/input/uou-ie-g-03874-spring-2025-term-project/ML_y_train.csv')

x_train

y_train

x_test

"""# 데이터 분석

[참고] Credit Score Classification Part:1 Data Cleaning

 - https://www.kaggle.com/code/clkmuhammed/credit-score-classification-part-1-data-cleaning#B.-Examining-the-Data
"""

# 숫자를 지수표기법(e) 대신 소수점 두 자리로 표시
pd.options.display.float_format = '{:.2f}'.format

# train/test 데이터 크기 확인
x_train.shape, x_test.shape

x_train.info()

x_test.info()

y_train.info()

x_train.describe().T

# std는 표준편차, mean 평균, min 최소, max 최대

x_test.describe().T

y_train.describe().T

"""# 데이터 전처리

## 1. 데이터 통합 (x_train/test)
"""

# train/test 데이터 통합 (데이터 전처리하고 다시 분리 예정)
x_train['is_train'] = 1
x_test['is_train'] = 0
x = pd.concat([x_train, x_test], ignore_index=True)
x.shape

x.describe().T

"""## 2. 결측치 확인"""

# 각 열 결측치 개수 확인
x.isna().sum()

# 각 열의 결측치 비율 확인
x.isnull().mean()*100

"""## 3. 이상치 확인"""

x_copy = x.copy()
x_copy.shape

x = x_copy
x.info()

# 이상치 boxplot 시각화
def plot_multiple_outliers(df):
    numeric_cols = df.select_dtypes(include=['number']).columns
    n = len(numeric_cols)

    plt.figure(figsize=(10, 2 * n))

    for i, col in enumerate(numeric_cols, 1):
        plt.subplot(n, 1, i)
        sns.boxplot(x=df[col])
        plt.title(f'Boxplot for {col}')
        plt.tight_layout()

    plt.show()

# 이상치 시각화 실행
plot_multiple_outliers(x)

"""## 4. 이상치, 결측값 리리

## Age
"""

# 이상치 처리 및 음수 제거: 20 ~ 100 범위 유효
x.loc[(x['Age'] < 20) | (x['Age'] > 100), 'Age'] = np.nan

# 결측값 처리: Occupation 그룹 기준 중앙값 대체
x['Age'] = x.groupby('Occupation')['Age'].transform(lambda x: x.ffill().bfill())
x['Age'].fillna(x['Age'].median(), inplace=True)

"""## Annual_Income"""

# 이상치 처리: 100만 이상 제거, 결측값 중앙값 대체
x.loc[x['Annual_Income'] > 1e6, 'Annual_Income'] = np.nan
x['Annual_Income'].fillna(x['Annual_Income'].median(), inplace=True)

"""## Monthly_Inhand_Salary"""

# 결측값 처리: Annual_Income 기반 유추
miss_salary = x['Monthly_Inhand_Salary'].isna()
x.loc[miss_salary, 'Monthly_Inhand_Salary'] = x.loc[miss_salary, 'Annual_Income'] / 12

"""## Num_Bank_Accounts"""

# 이상치 처리: 0~11 범위 외 제거, 결측값은 최빈값으로 대체
x.loc[(x['Num_Bank_Accounts'] < 0) | (x['Num_Bank_Accounts'] > 11), 'Num_Bank_Accounts'] = np.nan
x['Num_Bank_Accounts'].fillna(x['Num_Bank_Accounts'].mode()[0], inplace=True)

"""## Num_Credit_Card"""

# 이상치 처리: 11 초과 제거, 결측값은 최빈값으로 대체
x.loc[x['Num_Credit_Card'] > 11, 'Num_Credit_Card'] = np.nan
x['Num_Credit_Card'].fillna(x['Num_Credit_Card'].mode()[0], inplace=True)

"""## Interest_Rate"""

# 이상치 처리: 34 초과 제거, 결측값은 최빈값으로 대체
x.loc[x['Interest_Rate'] > 34, 'Interest_Rate'] = np.nan
x['Interest_Rate'].fillna(x['Interest_Rate'].mode()[0], inplace=True)

"""## Num_of_Loan"""

# 이상치 제거: 음수 및 9 초과 제거, 결측값 중앙값 대체
x.loc[(x['Num_of_Loan'] < 0) | (x['Num_of_Loan'] > 9), 'Num_of_Loan'] = np.nan
x['Num_of_Loan'].fillna(x['Num_of_Loan'].median(), inplace=True)

"""## Num_of_Delayed_Payment"""

# 이상치 제거: 음수 및 28 초과 제거, 중앙값 대체
x.loc[(x['Num_of_Delayed_Payment'] < 0) | (x['Num_of_Delayed_Payment'] > 28), 'Num_of_Delayed_Payment'] = np.nan
x['Num_of_Delayed_Payment'].fillna(x['Num_of_Delayed_Payment'].median(), inplace=True)

"""## Num_Credit_Inquiries"""

# 결측값 처리: 중앙값 대체
x['Num_Credit_Inquiries'].fillna(x['Num_Credit_Inquiries'].median(), inplace=True)

"""## Outstanding_Debt"""

# 결측값 처리: 중앙값 대체
x['Outstanding_Debt'].fillna(x['Outstanding_Debt'].median(), inplace=True)

"""## Credit_Utilization_Ratio"""

# 결측값 처리: 중앙값 대체
x['Credit_Utilization_Ratio'].fillna(x['Credit_Utilization_Ratio'].median(), inplace=True)

"""## Total_EMI_per_month"""

# 결측값 처리: 중앙값 대체
x['Total_EMI_per_month'].fillna(x['Total_EMI_per_month'].median(), inplace=True)

"""## Amount_invested_monthly"""

# 결측값 처리: 중앙값 대체
x['Amount_invested_monthly'].fillna(x['Amount_invested_monthly'].median(), inplace=True)

"""## Monthly_Balance"""

# 결측값 처리: 중앙값 대체
x['Monthly_Balance'].fillna(x['Monthly_Balance'].median(), inplace=True)

"""## Credit_History_Months"""

# 이상치 제거: 720개월 초과 제거, 중앙값 대체
x.loc[x['Credit_History_Months'] > 720, 'Credit_History_Months'] = np.nan
x['Credit_History_Months'].fillna(x['Credit_History_Months'].median(), inplace=True)

x['Num_of_Delayed_Payment'] = x['Num_of_Delayed_Payment'].apply(
    lambda val: 0 if pd.isna(val) or val < 0 else (50 if val > 50 else val)
)

# 이상치 boxplot 시각화
def plot_multiple_outliers(df):
    numeric_cols = df.select_dtypes(include=['number']).columns
    n = len(numeric_cols)

    plt.figure(figsize=(10, 2 * n))

    for i, col in enumerate(numeric_cols, 1):
        plt.subplot(n, 1, i)
        sns.boxplot(x=df[col])
        plt.title(f'Boxplot for {col}')
        plt.tight_layout()

    plt.show()

# 이상치 시각화 실행
plot_multiple_outliers(x)

# 이상치 클리핑 함수 (IQR 기반)
def clip_outliers(df, columns):
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)

# 클리핑 적용 대상 변수
clip_columns = [
    'Annual_Income', 'Delay_from_due_date', 'Num_Credit_Inquiries', 'Outstanding_Debt',
    'Monthly_Inhand_Salary', 'Credit_Utilization_Ratio', 'Total_EMI_per_month',
    'Amount_invested_monthly', 'Monthly_Balance', 'Num_Credit_Inquiries', 'Outstanding_Debt'
]

# 이상치 클리핑 실행
clip_outliers(x, clip_columns)

# 이상치 boxplot 시각화
def plot_multiple_outliers(df):
    numeric_cols = df.select_dtypes(include=['number']).columns
    n = len(numeric_cols)

    plt.figure(figsize=(10, 2 * n))

    for i, col in enumerate(numeric_cols, 1):
        plt.subplot(n, 1, i)
        sns.boxplot(x=df[col])
        plt.title(f'Boxplot for {col}')
        plt.tight_layout()

    plt.show()

# 이상치 시각화 실행
plot_multiple_outliers(x)

x

x.describe().T

x.isna().sum()

x.info()

"""## 5. 전처리 이후 데이터 분리"""

x['Delayed_Payment_Ratio'] = x['Num_of_Delayed_Payment'] / (x['Credit_History_Months'] + 1)
x['Balance_to_EMI'] = x['Monthly_Balance'] / (x['Total_EMI_per_month'] + 1)
x['Salary_Ratio'] = x['Monthly_Inhand_Salary'] / (x['Monthly_Balance'] + 1)

# is_train 값이 1인 데이터는 학습용, 0인 데이터는 테스트용으로 분리
# 분리 후 'is_train' 컬럼은 필요 없으므로 drop
x_train = x[x['is_train'] == 1].drop(columns='is_train')
x_test = x[x['is_train'] == 0].drop(columns='is_train')

x_train.shape, x_test.shape

x_train.info()

x_test.info()

"""## 6. 변수 상관관계 분석

[참고] Credit Score Multi-Class Classification Part:2 ML

 - https://www.kaggle.com/code/clkmuhammed/credit-score-multi-class-classification-part-2-ml#Import-Libraries
"""

# 변수 간 상관관계
plt.figure(figsize=(14, 10))
corr = x_train.corr()
mask = np.triu(np.ones_like(corr, dtype=bool))  # 상위 삼각형 마스크 생성

sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', square=True, vmin=-1, vmax=1)

plt.title("Correlation Heatmap")
plt.tight_layout()
plt.show()

train = pd.concat([x_train, y_train], axis=1)

plt.figure(figsize=(6, 4))
sns.countplot(x='Credit_Score', data=train, palette='Set2')

plt.xlabel('Credit Class')
plt.ylabel('Count')
plt.show()

# 수치형 변수 자동 선택
numeric_cols = train.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Credit_Score는 범주형 기준이므로 제외하지 않음
ncols = 3
nrows = (len(numeric_cols) + ncols - 1) // ncols
plt.figure(figsize=(16, 5 * nrows))

for i, col in enumerate(numeric_cols):
    plt.subplot(nrows, ncols, i + 1)
    sns.boxplot(data=train, x='Credit_Score', y=col, palette='Set2')
    plt.title(f'{col}')

plt.tight_layout()
plt.show()

# # 제거할 변수
# x_train.drop(columns=['Annual_Income'], inplace=True)
# x_test.drop(columns=['Annual_Income'], inplace=True)

"""# 모델링

## 1. SHAP 시각화

[참고] XGBoost explainability with SHAP
https://www.kaggle.com/code/bryanb/xgboost-explainability-with-shap

머신러닝 모델은 예측 정확도는 높지만, 그 결과가 왜 그렇게 나왔는지 해석하기 어려운 경우가 많습니다.
특히 XGBoost, RandomForest, CatBoost 같은 복잡한 앙상블 모델은 내부 구조가 블랙박스처럼 작동하여,
각 피처가 예측에 어떤 영향을 주었는지 파악하기 힘든 문제가 발생합니다.

즉, 모델은 잘 작동하고 있지만, '왜 그렇게 예측했는가?'에 대한 설명이 부족하기 때문에
결정에 대한 신뢰도가 떨어지고, 실제 적용 현장에서 문제가 발생할 수 있습니다.

이러한 상황에서 SHAP은 각 피처가 예측 결과에 얼마나, 어떻게 영향을 미쳤는지를 정량적으로 설명해줍니다.
각 피처의 기여도를 수치로 표현할 뿐만 아니라, 이를 직관적인 시각화로 제공하여
복잡한 모델의 예측 과정을 사람도 이해할 수 있도록 돕는 도구입니다.
"""

# 중요 변수 선택 전 XGBoost 학습
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
xgb_model.fit(x_train, y_train.values.ravel())

# SHAP 시각화
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(x_train)

shap.summary_plot(shap_values, x_train, plot_type="bar")

# 중요 변수 14개 추출 및 선택
importance = xgb_model.feature_importances_
importance_df = pd.DataFrame({'feature': x_train.columns, 'importance': importance})
selected_c = importance_df.sort_values(by='importance', ascending=False)['feature'].head(15).tolist()

x_train_top = x_train[selected_c].copy()
x_test_top = x_test[selected_c].copy()

# 클래스 가중치 자동 계산
class_weights = compute_class_weight(class_weight='balanced',
                                     classes=np.unique(y_train['Credit_Score']),
                                     y=y_train['Credit_Score'])

# 딕셔너리 형태로 변환
class_weight_dict = dict(zip(np.unique(y_train['Credit_Score']), class_weights))
print("클래스 가중치:", class_weight_dict)

"""## 2. SMOTE 적용

[참고] IQR을 이용한 Outlier 탐지 + SMOTE Oversampling
 - https://www.kaggle.com/code/dogdriip/iqr-outlier-smote-oversampling/code#SMOTE-%EC%98%A4%EB%B2%84%EC%83%98%ED%94%8C%EB%A7%81-%EC%A0%81%EC%9A%A9


**SMOTE 오버샘플링 적용**

레이블이 불균형한 분포를 가진 데이터 세트를 학습시킬 때 예측 성능의 문제가 발생할 수 있는데, 이는 이상 레이블을 가지는 데이터 건수가 정상 레이블을 가진 데이터 건수에 비해 너무 적기 때문에 발생합니다. 즉 이상 레이블을 가지는 데이터 건수는 매우 적기 때문에 제대로 다양한 유형을 학습하지 못하는 반면, 정상 레이블을 가지는 데이터 건수는 매우 많기 때문에 일방적으로 정상 레이블로 치우친 학습을 수행해 제대로 된 이상 데이터 검출이 어려워지기 쉽습니다.

오버 샘플링은 이상 데이터와 같이 적은 데이터 세트를 증식하여 학습을 위한 충분한 데이터를 확보하는 방법입니다. 원본 데이터의 피쳐 값들을 아주 약간만 변경하여 증식합니다. 대표적으로 SMOTE(Synthetic Minority Over-sampling Technique) 방법이 있습니다. SMOTE는 적은 데이터 세트에 있는 개별 데이터들의 K-Nearest-Neighbor를 찾아서 이 데이터와 K개 이웃들의 차이를 일정 값으로 만들어서 기존 데이터와 약간 차이가 나는 새로운 데이터들을 생성하는 방식입니다.
"""

# 데이터 분할 → SMOTE는 학습 데이터에만 먼저 적용
x_trn, x_val, y_trn, y_val = train_test_split(
    x_train_top, y_train['Credit_Score'], test_size=0.2, random_state=42, stratify=y_train['Credit_Score'])
# x_trn_sm, y_trn_sm = SMOTE(random_state=42).fit_resample(x_trn, y_trn)

"""## 3. 각 모델 선정 및 최적 하이퍼파라미터 설정"""

# 각 모델과 최적 하이퍼파라미터 설정
rf = RandomForestClassifier(random_state=42, class_weight=class_weight_dict)
rf_params = {
    'n_estimators': [200, 300],
    'max_depth': [15, 20],
    'min_samples_split': [2, 4],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt']
}

xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
xgb_params = {
    'n_estimators': [200, 300],
    'learning_rate': [0.03, 0.05],
    'max_depth': [6, 8],
    'subsample': [0.8],
    'colsample_bytree': [1.0],
    'gamma': [0.1, 0.3]
}

gb = GradientBoostingClassifier(random_state=42)
gb_params = {
    'n_estimators': [100, 200],
    'max_depth': [5, 6],
    'learning_rate': [0.01, 0.05],
    'subsample': [0.6, 0.8]
}

# 모델별 RandomizedSearchCV 실행하여 최적 하이퍼파라미터 선정
def tune_model(model, param_grid, name='model'):
    search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=20,
                                scoring='f1_macro', cv=3, verbose=1, random_state=42, n_jobs=-1)
    search.fit(x_trn, y_trn)

    # 최적 하이퍼파라미터 출력 및 저장
    print(f"\n{name} Best Params:", search.best_params_)
    return search.best_estimator_, search.best_params_

# 하이퍼파라미터 튜닝 실행
print("\nRandomForest")
best_rf, best_rf_params = tune_model(rf, rf_params, name="RandomForest")

print("\nXGBoost")
best_xgb, best_xgb_params = tune_model(xgb, xgb_params, name="XGBoost")

print("\nGradientBoosting")
best_gb, best_gb_params = tune_model(gb, gb_params, name="GradientBoosting")

"""## 4. 개별 모델별 성능 평가"""

def evaluate_model(name, model, x_data, y_data):
    model.fit(x_data, y_data)
    y_pred = model.predict(x_data)
    acc = accuracy_score(y_data, y_pred)
    f1 = f1_score(y_data, y_pred, average='macro')
    print(f"\n[{name}]")
    print("Accuracy:", acc)
    print("Macro F1:", f1)
    print(classification_report(y_data, y_pred))

evaluate_model("RandomForest", best_rf, x_trn, y_trn)
evaluate_model("XGBoost", best_xgb, x_trn, y_trn)
evaluate_model("GradientBoosting", best_gb, x_trn, y_trn)

base_models = [
    ('rf', best_rf),
    ('xgb', best_xgb),
    ('gb', best_gb),
]

meta_model = XGBClassifier(
    **best_xgb_params,
    reg_alpha=0.3,        # L1 penalty
    reg_lambda=1.0,       # L2 penalty
    use_label_encoder=False,
    eval_metric='mlogloss',
    random_state=42
)

stack_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    stack_method='predict',
    cv=5,
    passthrough=True,
    n_jobs=-1
)

# StratifiedKFold로 검증
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

acc_scores = []
f1_scores = []

for fold, (train_idx, valid_idx) in enumerate(skf.split(x_train, y_train), 1):
    X_tr, X_val = x_train.iloc[train_idx], x_train.iloc[valid_idx]
    y_tr, y_val = y_train.iloc[train_idx].values.ravel(), y_train.iloc[valid_idx].values.ravel()

    # fold마다 새로운 stacking model 생성
    fold_stack_model = StackingClassifier(
        estimators=base_models,
        final_estimator=meta_model,
        stack_method='predict',      # 성능 좋았던 설정 유지
        passthrough=True,            # 원본 feature도 사용
        cv=5,
        n_jobs=-1
    )

    fold_stack_model.fit(X_tr, y_tr)
    val_preds = fold_stack_model.predict(X_val)

    acc = accuracy_score(y_val, val_preds)
    f1 = f1_score(y_val, val_preds, average='macro')

    acc_scores.append(acc)
    f1_scores.append(f1)

    print(f"[Fold {fold}] Accuracy: {acc:.4f}, Macro F1: {f1:.4f}")

print(f"\nK-Fold Accuracy: {np.mean(acc_scores):.4f}")
print(f"K-Fold Macro F1: {np.mean(f1_scores):.4f}")

"""## 5. Enseble 앙상블"""

# # 최종 앙상블 구성 (좋은 모델만)
# ensemble = VotingClassifier(estimators=[
#     ('xgb', best_xgb),
#     ('rf', best_rf),
# ], voting='soft')

# # 앙상블 평가
# ensemble.fit(x_trn, y_trn)
# y_pred = ensemble.predict(x_trn)

# acc = accuracy_score(y_trn, y_pred)
# f1 = f1_score(y_trn, y_pred, average='macro')

# print("Accuracy:", acc)
# print("Macro F1:", f1)
# print(classification_report(y_trn, y_pred))

"""## 6. K-Fold 평가"""

# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
# acc_list, f1_list = [], []

# for fold, (train_idx, val_idx) in enumerate(kf.split(x_trn, y_trn), 1):
#     x_fold_trn, x_fold_val = x_trn.iloc[train_idx], x_trn.iloc[val_idx]
#     y_fold_trn, y_fold_val = y_trn.iloc[train_idx], y_trn.iloc[val_idx]

#     ensemble.fit(x_fold_trn, y_fold_trn)
#     y_pred = ensemble.predict(x_fold_val)

#     acc = accuracy_score(y_fold_val, y_pred)
#     f1 = f1_score(y_fold_val, y_pred, average='macro')
#     acc_list.append(acc)
#     f1_list.append(f1)

#     print(f"[Fold {fold}] Accuracy: {acc:.4f}, Macro F1: {f1:.4f}")

# print(f"\nK-Fold Accuracy: {np.mean(acc_list):.4f}")
# print(f"K-Fold Macro F1: {np.mean(f1_list):.4f}")

stack_model.fit(x_train, y_train)
# 스택 모델이 학습 데이터에서 예측한 결과
y_true = y_train.values.ravel() if hasattr(y_train, 'values') else y_train
y_pred_stack = stack_model.predict(x_train)

# 오분류 인덱스
mis_idx = np.where(y_true != y_pred_stack)[0]
print(f"예측 실패 샘플 수: {len(mis_idx)} / {len(y_true)}")

# 클래스별 실패 분포
fail_df = pd.DataFrame({
    'True': y_true[mis_idx],
    'Pred': y_pred_stack[mis_idx]
})
print("\n실패 클래스 조합 (True → Pred):")
print(fail_df.value_counts().sort_values(ascending=False))

# confusion matrix
print("\nConfusion Matrix:")
print(confusion_matrix(y_true, y_pred_stack))

# 오분류 샘플 데이터 보기
fail_features = x_train.iloc[mis_idx].copy()
fail_features['True'] = y_true[mis_idx]
fail_features['Pred'] = y_pred_stack[mis_idx]

# 특정 혼동 사례 보기 (예: True=1, Pred=0)
example = fail_features[(fail_features['True'] == 1) & (fail_features['Pred'] == 0)]
print("\n클래스 1을 0으로 잘못 예측한 사례 수:", len(example))

"""# Submission 결과 제출"""

np.random.seed(42)

x_test_aligned = x_test[x_train.columns.tolist()].copy()

best_rf.fit(x_train, y_train)
best_xgb.fit(x_train, y_train)

stack_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    stack_method='predict',
    passthrough=True,
    cv=5,
    n_jobs=-1
)
stack_model.fit(x_train, y_train)

pred_rf = best_rf.predict(x_test_aligned)
pred_xgb = best_xgb.predict(x_test_aligned)
pred_stack = stack_model.predict(x_test_aligned)

all_preds = np.vstack([
    pred_rf,
    pred_rf,
    pred_rf,
    pred_xgb,
    pred_stack
])

pred_test, _ = mode(all_preds, axis=0)
pred_test = pred_test.flatten()


# 확률 기반 후처리용 predict_proba
proba_stack = stack_model.predict_proba(x_test_aligned)

# 교정된 예측 결과 복사
pred_test_corrected = pred_test.copy()

# class 2 확신이 낮은 경우 → class 1로 교정
for i in range(len(pred_test)):
    if (
        pred_test[i] == 2
        and proba_stack[i][2] < 0.35
        and pred_rf[i] == 1
        and pred_xgb[i] == 1
    ):
        pred_test[i] = 1

print("교정 전 class 2 예측 개수:", np.sum(pred_test == 2))
print("교정 후 class 2 예측 개수:", np.sum(pred_test_corrected == 2))

# 제출 파일 템플릿 로드
result = pd.read_csv('/kaggle/input/uou-ie-g-03874-spring-2025-term-project/ML_sample_submission.csv')

# 예측 결과 삽입
result['Credit_Score'] = pred_test_corrected

# 저장
result.to_csv('submission.csv', index=False)